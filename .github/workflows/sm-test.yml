name: Test State Machine

run-name: "${{ inputs.scenario_name }} (${{ inputs.start_step && format('{0}→End', inputs.start_step) || 'Beginning→End' }}) | Claude: ${{ inputs.mock_claude && 'mock' || 'real' }} | CI: ${{ inputs.mock_ci && 'mock' || 'real' }} | ${{ inputs.multi_issue && 'multi' || 'single' }}${{ inputs.continue == false && ' | single-step' || '' }}"

on:
  workflow_dispatch:
    inputs:
      scenario_name:
        description: 'Scenario to run (directory name under test-fixtures/scenarios/)'
        required: true
        type: choice
        options:
          - full-flow
          - ci-failure-recovery
          - triage
          - circuit-breaker
          - review-changes-requested
          - triage-with-subissues
          - issue-comment
          - issue-reset
          - slash-lfg
          - pr-review-comment
          - pr-review-approved
          - pr-push-during-review
          - grooming-ready
          - pivot-simple
          - pivot-add
          - pivot-remove
          - pivot-revert
          - pivot-complex
      continue:
        description: 'Run to completion (true) or stop after one step (false)'
        type: boolean
        default: true
      mock_claude:
        description: 'Mock Claude outputs from fixture files'
        type: boolean
        default: true
      mock_ci:
        description: 'Mock CI (immediate pass/fail based on fixture)'
        type: boolean
        default: true
      start_step:
        description: 'Start at a specific state (e.g., "iteratingFix"). Creates fresh issue, sets up GitHub to match that state fixture.'
        type: string
        required: false
      multi_issue:
        description: 'Create multiple sub-issues (true) or single issue (false). Multi tests full orchestration flow.'
        type: boolean
        default: true
      cleanup_only:
        description: 'Only run cleanup (for debugging)'
        type: boolean
        default: false
      issue_number:
        description: 'Issue number for cleanup_only mode'
        type: string
        default: ''
      cleanup_mode:
        description: 'Cleanup mode: close (preserves history) or delete (permanent removal)'
        type: choice
        options:
          - close
          - delete
        default: close

# Per-scenario concurrency - allows parallel testing of different scenarios
concurrency:
  group: state-machine-test-${{ inputs.scenario_name }}
  cancel-in-progress: false

permissions:
  contents: write
  pull-requests: write
  issues: write
  actions: write
  id-token: write

env:
  GH_TOKEN: ${{ secrets.NOPO_BOT_PAT || secrets.GITHUB_TOKEN }}

jobs:
  # Run the configurable test
  run:
    if: inputs.cleanup_only != true
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.run.outputs.status }}
      issue_number: ${{ steps.run.outputs.issue_number }}
      transitions: ${{ steps.run.outputs.transitions }}
      total_duration_ms: ${{ steps.run.outputs.total_duration_ms }}
      error: ${{ steps.run.outputs.error }}
    steps:
      # Validate that edge case scenarios don't use Real Claude
      # These scenarios require Claude to intentionally create failures, which is unreliable
      - name: Validate mock_claude for edge cases
        if: inputs.mock_claude == false
        run: |
          EDGE_CASES="ci-failure-recovery circuit-breaker review-changes-requested"
          SCENARIO="${{ inputs.scenario_name }}"

          for edge_case in $EDGE_CASES; do
            if [[ "$SCENARIO" == "$edge_case" ]]; then
              echo "::error::Scenario '$SCENARIO' requires mock_claude=true"
              echo ""
              echo "Edge case scenarios (ci-failure-recovery, circuit-breaker, review-changes-requested)"
              echo "test system behavior in response to failures, not Claude's ability to create bugs."
              echo "These scenarios only support Mock Claude mode."
              exit 1
            fi
          done

          echo "✓ Real Claude mode allowed for scenario: $SCENARIO"

      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Compile prompts
        run: pnpm --filter @more/prompts compile

      - name: Build actions
        run: |
          cd .github/actions-ts
          pnpm run build

      # Install Claude Code when running in non-mock mode (SDK requires it)
      # Use official installer per: https://platform.claude.com/docs/en/agent-sdk/quickstart
      # Binary installed to ~/.local/bin/claude
      - name: Install Claude Code
        if: inputs.mock_claude != true
        run: |
          set -e
          echo "Installing Claude Code..."
          curl -fsSL https://claude.ai/install.sh | bash
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

          # Verify installation
          if [ -f "$HOME/.local/bin/claude" ]; then
            echo "✓ Claude Code installed at $HOME/.local/bin/claude"
            "$HOME/.local/bin/claude" --version || echo "Warning: Could not get version"
          else
            echo "::error::Claude Code installation failed - binary not found at $HOME/.local/bin/claude"
            ls -la "$HOME/.local/bin/" || echo "Directory does not exist"
            exit 1
          fi

      - name: Run configurable test
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          # Explicit path for Claude Code (in case PATH isn't updated in Node.js process)
          CLAUDE_CODE_PATH: /home/runner/.local/bin/claude
        id: run
        uses: ./packages/statemachine/actions/sm-test-runner
        with:
          action: run-configurable
          scenario_name: ${{ inputs.scenario_name }}
          continue: ${{ inputs.continue }}
          mock_claude: ${{ inputs.mock_claude }}
          mock_ci: ${{ inputs.mock_ci }}
          start_step: ${{ inputs.start_step }}
          multi_issue: ${{ inputs.multi_issue }}
          github_token: ${{ secrets.NOPO_BOT_PAT }}
          reviewer_token: ${{ secrets.CLAUDE_REVIEWER_PAT }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}

      - name: Output results
        env:
          STATUS: ${{ steps.run.outputs.status }}
          ISSUE_NUMBER: ${{ steps.run.outputs.issue_number }}
          TRANSITIONS: ${{ steps.run.outputs.transitions }}
          TOTAL_DURATION: ${{ steps.run.outputs.total_duration_ms }}
          ERROR: ${{ steps.run.outputs.error }}
        run: |
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Scenario** | ${{ inputs.scenario_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Status** | \`${STATUS}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Issue** | #${ISSUE_NUMBER} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Duration** | ${TOTAL_DURATION}ms |" >> $GITHUB_STEP_SUMMARY

          if [[ -n "$ERROR" ]]; then
            echo "| **Error** | ${ERROR} |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Continue** | ${{ inputs.continue }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Mock Claude** | ${{ inputs.mock_claude }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Mock CI** | ${{ inputs.mock_ci }} |" >> $GITHUB_STEP_SUMMARY
          if [[ -n "${{ inputs.start_step }}" ]]; then
            echo "| **Start Step** | ${{ inputs.start_step }} |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Transitions" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo "$TRANSITIONS" | jq '.' >> $GITHUB_STEP_SUMMARY || echo "$TRANSITIONS" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # Cleanup test artifacts
  cleanup:
    needs: [run]
    if: always() && (needs.run.outputs.issue_number != '' || inputs.cleanup_only == true)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      - name: Build test helper action
        run: |
          cd .github/actions-ts
          pnpm install --frozen-lockfile
          pnpm run build

      - name: Determine issue number
        id: issue
        run: |
          if [[ "${{ inputs.cleanup_only }}" == "true" ]]; then
            issue_number="${{ inputs.issue_number }}"
            if [[ -z "$issue_number" ]]; then
              echo "::error::issue_number is required for cleanup_only mode"
              exit 1
            fi
          else
            issue_number="${{ needs.run.outputs.issue_number }}"
          fi
          echo "issue_number=$issue_number" >> $GITHUB_OUTPUT

      - name: Cleanup test fixture
        uses: ./packages/statemachine/actions/sm-test-helper
        with:
          action: cleanup
          issue_number: ${{ steps.issue.outputs.issue_number }}
          github_token: ${{ env.GH_TOKEN }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}
          cleanup_mode: ${{ inputs.cleanup_mode || 'close' }}

      - name: Output cleanup result
        run: |
          echo "## Cleanup Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Cleaned up issue #${{ steps.issue.outputs.issue_number }} and related resources." >> $GITHUB_STEP_SUMMARY

  # Summary job
  summary:
    needs: [run, cleanup]
    if: always() && inputs.cleanup_only != true
    runs-on: ubuntu-latest
    steps:
      - name: Generate summary
        env:
          STATUS: ${{ needs.run.outputs.status }}
          TRANSITIONS: ${{ needs.run.outputs.transitions }}
          DURATION: ${{ needs.run.outputs.total_duration_ms }}
          ERROR: ${{ needs.run.outputs.error }}
        run: |
          echo "# State Machine Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Scenario** | ${{ inputs.scenario_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Issue** | #${{ needs.run.outputs.issue_number }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Status** | \`${STATUS:-N/A}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Duration** | ${DURATION:-0}ms |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Continue** | ${{ inputs.continue }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Mock Claude** | ${{ inputs.mock_claude }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Mock CI** | ${{ inputs.mock_ci }} |" >> $GITHUB_STEP_SUMMARY
          if [[ -n "${{ inputs.start_step }}" ]]; then
            echo "| **Start Step** | ${{ inputs.start_step }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ -n "$ERROR" ]]; then
            echo "### Error" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "$ERROR" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          echo "## Job Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Run | ${{ needs.run.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Cleanup | ${{ needs.cleanup.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**State-based fixture testing with mocked or real Claude/CI.**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Each state transition was:" >> $GITHUB_STEP_SUMMARY
          echo "1. Set up from the state fixture" >> $GITHUB_STEP_SUMMARY
          echo "2. Executed (with mocked or real Claude/CI)" >> $GITHUB_STEP_SUMMARY
          echo "3. Verified against the next state fixture" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Use \`continue=false\` for step-by-step debugging." >> $GITHUB_STEP_SUMMARY
          echo "Use \`start_step\` to start at a specific state." >> $GITHUB_STEP_SUMMARY
