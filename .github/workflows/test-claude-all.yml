name: Test All Scenarios with Claude Analysis

run-name: "All Scenarios | ${{ inputs.include_real_claude && 'Mock + Real Claude' || 'Mock Only' }}"

on:
  workflow_dispatch:
    inputs:
      include_real_claude:
        description: 'Include real Claude tests (in addition to mock tests)'
        type: boolean
        default: true
      max_parallel:
        description: 'Max parallel jobs per batch'
        type: number
        default: 5

permissions:
  contents: write
  pull-requests: write
  issues: write
  actions: write
  id-token: write

env:
  GH_TOKEN: ${{ secrets.NOPO_BOT_PAT || secrets.GITHUB_TOKEN }}

jobs:
  # ============================================================================
  # BATCH 1: Core scenarios (mock Claude)
  # ============================================================================
  batch1-mock:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix:
        scenario:
          - full-flow
          - triage
          - grooming-ready
          - pivot-simple
          - issue-comment
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: pnpm/action-setup@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm --filter @more/prompts compile
      - name: Build actions
        run: cd .github/actions-ts && pnpm run build

      - name: Run test
        id: run
        continue-on-error: true
        uses: ./packages/statemachine/actions/sm-test-runner
        with:
          action: run-configurable
          scenario_name: ${{ matrix.scenario }}
          continue: true
          mock_claude: true
          mock_ci: true
          multi_issue: true
          github_token: ${{ secrets.NOPO_BOT_PAT }}
          reviewer_token: ${{ secrets.CLAUDE_REVIEWER_PAT }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}

      - name: Cleanup
        if: always() && steps.run.outputs.issue_number != ''
        uses: ./packages/statemachine/actions/sm-test-helper
        with:
          action: cleanup
          issue_number: ${{ steps.run.outputs.issue_number }}
          github_token: ${{ env.GH_TOKEN }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}
          cleanup_mode: close

      - name: Save result
        if: always()
        env:
          SCENARIO: ${{ matrix.scenario }}
          STATUS: ${{ steps.run.outputs.status || 'error' }}
          ISSUE_NUMBER: ${{ steps.run.outputs.issue_number || '' }}
          ERROR_MSG: ${{ steps.run.outputs.error || '' }}
          JOB_RESULT: ${{ job.status }}
        run: |
          mkdir -p results
          jq -n \
            --arg scenario "$SCENARIO" \
            --arg mode "mock" \
            --arg batch "batch1-mock" \
            --arg status "$STATUS" \
            --arg issue_number "$ISSUE_NUMBER" \
            --arg error "$ERROR_MSG" \
            --arg job_result "$JOB_RESULT" \
            '{scenario: $scenario, mode: $mode, batch: $batch, status: $status, issue_number: $issue_number, error: $error, job_result: $job_result}' \
            > results/${{ matrix.scenario }}-mock.json

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: result-batch1-${{ matrix.scenario }}
          path: results/
          retention-days: 1

      - name: Fail job if test failed
        if: always() && steps.run.outputs.status != 'completed'
        run: |
          echo "Test failed with status: ${{ steps.run.outputs.status }}"
          echo "Error: ${{ steps.run.outputs.error }}"
          exit 1

  # ============================================================================
  # BATCH 2: Edge case scenarios (mock Claude only - these REQUIRE mock)
  # ============================================================================
  batch2-edge-cases:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix:
        scenario:
          - ci-failure-recovery
          - circuit-breaker
          - review-changes-requested
          - issue-reset
          - slash-lfg
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: pnpm/action-setup@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm --filter @more/prompts compile
      - name: Build actions
        run: cd .github/actions-ts && pnpm run build

      - name: Run test
        id: run
        continue-on-error: true
        uses: ./packages/statemachine/actions/sm-test-runner
        with:
          action: run-configurable
          scenario_name: ${{ matrix.scenario }}
          continue: true
          mock_claude: true
          mock_ci: true
          multi_issue: true
          github_token: ${{ secrets.NOPO_BOT_PAT }}
          reviewer_token: ${{ secrets.CLAUDE_REVIEWER_PAT }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}

      - name: Cleanup
        if: always() && steps.run.outputs.issue_number != ''
        uses: ./packages/statemachine/actions/sm-test-helper
        with:
          action: cleanup
          issue_number: ${{ steps.run.outputs.issue_number }}
          github_token: ${{ env.GH_TOKEN }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}
          cleanup_mode: close

      - name: Save result
        if: always()
        env:
          SCENARIO: ${{ matrix.scenario }}
          STATUS: ${{ steps.run.outputs.status || 'error' }}
          ISSUE_NUMBER: ${{ steps.run.outputs.issue_number || '' }}
          ERROR_MSG: ${{ steps.run.outputs.error || '' }}
          JOB_RESULT: ${{ job.status }}
        run: |
          mkdir -p results
          jq -n \
            --arg scenario "$SCENARIO" \
            --arg mode "mock" \
            --arg batch "batch2-edge-cases" \
            --arg status "$STATUS" \
            --arg issue_number "$ISSUE_NUMBER" \
            --arg error "$ERROR_MSG" \
            --arg job_result "$JOB_RESULT" \
            '{scenario: $scenario, mode: $mode, batch: $batch, status: $status, issue_number: $issue_number, error: $error, job_result: $job_result}' \
            > results/${{ matrix.scenario }}-mock.json

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: result-batch2-${{ matrix.scenario }}
          path: results/
          retention-days: 1

      - name: Fail job if test failed
        if: always() && steps.run.outputs.status != 'completed'
        run: |
          echo "Test failed with status: ${{ steps.run.outputs.status }}"
          echo "Error: ${{ steps.run.outputs.error }}"
          exit 1

  # ============================================================================
  # BATCH 3: PR and pivot scenarios (mock Claude)
  # ============================================================================
  batch3-mock:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix:
        scenario:
          - pr-review-approved
          - pr-review-comment
          - pr-push-during-review
          - pivot-add
          - pivot-remove
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: pnpm/action-setup@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm --filter @more/prompts compile
      - name: Build actions
        run: cd .github/actions-ts && pnpm run build

      - name: Run test
        id: run
        continue-on-error: true
        uses: ./packages/statemachine/actions/sm-test-runner
        with:
          action: run-configurable
          scenario_name: ${{ matrix.scenario }}
          continue: true
          mock_claude: true
          mock_ci: true
          multi_issue: true
          github_token: ${{ secrets.NOPO_BOT_PAT }}
          reviewer_token: ${{ secrets.CLAUDE_REVIEWER_PAT }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}

      - name: Cleanup
        if: always() && steps.run.outputs.issue_number != ''
        uses: ./packages/statemachine/actions/sm-test-helper
        with:
          action: cleanup
          issue_number: ${{ steps.run.outputs.issue_number }}
          github_token: ${{ env.GH_TOKEN }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}
          cleanup_mode: close

      - name: Save result
        if: always()
        env:
          SCENARIO: ${{ matrix.scenario }}
          STATUS: ${{ steps.run.outputs.status || 'error' }}
          ISSUE_NUMBER: ${{ steps.run.outputs.issue_number || '' }}
          ERROR_MSG: ${{ steps.run.outputs.error || '' }}
          JOB_RESULT: ${{ job.status }}
        run: |
          mkdir -p results
          jq -n \
            --arg scenario "$SCENARIO" \
            --arg mode "mock" \
            --arg batch "batch3-mock" \
            --arg status "$STATUS" \
            --arg issue_number "$ISSUE_NUMBER" \
            --arg error "$ERROR_MSG" \
            --arg job_result "$JOB_RESULT" \
            '{scenario: $scenario, mode: $mode, batch: $batch, status: $status, issue_number: $issue_number, error: $error, job_result: $job_result}' \
            > results/${{ matrix.scenario }}-mock.json

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: result-batch3-${{ matrix.scenario }}
          path: results/
          retention-days: 1

      - name: Fail job if test failed
        if: always() && steps.run.outputs.status != 'completed'
        run: |
          echo "Test failed with status: ${{ steps.run.outputs.status }}"
          echo "Error: ${{ steps.run.outputs.error }}"
          exit 1

  # ============================================================================
  # BATCH 4: Complex pivot scenarios (mock Claude)
  # ============================================================================
  batch4-mock:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix:
        scenario:
          - pivot-revert
          - pivot-complex
          - grooming-with-subissues
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: pnpm/action-setup@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm --filter @more/prompts compile
      - name: Build actions
        run: cd .github/actions-ts && pnpm run build

      - name: Run test
        id: run
        continue-on-error: true
        uses: ./packages/statemachine/actions/sm-test-runner
        with:
          action: run-configurable
          scenario_name: ${{ matrix.scenario }}
          continue: true
          mock_claude: true
          mock_ci: true
          multi_issue: true
          github_token: ${{ secrets.NOPO_BOT_PAT }}
          reviewer_token: ${{ secrets.CLAUDE_REVIEWER_PAT }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}

      - name: Cleanup
        if: always() && steps.run.outputs.issue_number != ''
        uses: ./packages/statemachine/actions/sm-test-helper
        with:
          action: cleanup
          issue_number: ${{ steps.run.outputs.issue_number }}
          github_token: ${{ env.GH_TOKEN }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}
          cleanup_mode: close

      - name: Save result
        if: always()
        env:
          SCENARIO: ${{ matrix.scenario }}
          STATUS: ${{ steps.run.outputs.status || 'error' }}
          ISSUE_NUMBER: ${{ steps.run.outputs.issue_number || '' }}
          ERROR_MSG: ${{ steps.run.outputs.error || '' }}
          JOB_RESULT: ${{ job.status }}
        run: |
          mkdir -p results
          jq -n \
            --arg scenario "$SCENARIO" \
            --arg mode "mock" \
            --arg batch "batch4-mock" \
            --arg status "$STATUS" \
            --arg issue_number "$ISSUE_NUMBER" \
            --arg error "$ERROR_MSG" \
            --arg job_result "$JOB_RESULT" \
            '{scenario: $scenario, mode: $mode, batch: $batch, status: $status, issue_number: $issue_number, error: $error, job_result: $job_result}' \
            > results/${{ matrix.scenario }}-mock.json

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: result-batch4-${{ matrix.scenario }}
          path: results/
          retention-days: 1

      - name: Fail job if test failed
        if: always() && steps.run.outputs.status != 'completed'
        run: |
          echo "Test failed with status: ${{ steps.run.outputs.status }}"
          echo "Error: ${{ steps.run.outputs.error }}"
          exit 1

  # ============================================================================
  # BATCH 5: Real Claude tests (only if include_real_claude is true)
  # Tests core scenarios with actual Claude to verify real behavior
  # ============================================================================
  batch5-real-claude:
    if: inputs.include_real_claude == true
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix:
        scenario:
          - full-flow
          - triage
          - pivot-simple
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: pnpm/action-setup@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm --filter @more/prompts compile
      - name: Build actions
        run: cd .github/actions-ts && pnpm run build

      - name: Install Claude Code
        run: |
          set -e
          echo "Installing Claude Code..."
          curl -fsSL https://claude.ai/install.sh | bash
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          if [ -f "$HOME/.local/bin/claude" ]; then
            echo "✓ Claude Code installed at $HOME/.local/bin/claude"
            "$HOME/.local/bin/claude" --version || echo "Warning: Could not get version"
          else
            echo "::error::Claude Code installation failed"
            exit 1
          fi

      - name: Run test
        id: run
        continue-on-error: true
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          CLAUDE_CODE_PATH: /home/runner/.local/bin/claude
        uses: ./packages/statemachine/actions/sm-test-runner
        with:
          action: run-configurable
          scenario_name: ${{ matrix.scenario }}
          continue: true
          mock_claude: false
          mock_ci: true
          multi_issue: true
          github_token: ${{ secrets.NOPO_BOT_PAT }}
          reviewer_token: ${{ secrets.CLAUDE_REVIEWER_PAT }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}

      - name: Cleanup
        if: always() && steps.run.outputs.issue_number != ''
        uses: ./packages/statemachine/actions/sm-test-helper
        with:
          action: cleanup
          issue_number: ${{ steps.run.outputs.issue_number }}
          github_token: ${{ env.GH_TOKEN }}
          project_number: ${{ vars.PROJECT_NUMBER || '1' }}
          cleanup_mode: close

      - name: Save result
        if: always()
        env:
          SCENARIO: ${{ matrix.scenario }}
          STATUS: ${{ steps.run.outputs.status || 'error' }}
          ISSUE_NUMBER: ${{ steps.run.outputs.issue_number || '' }}
          ERROR_MSG: ${{ steps.run.outputs.error || '' }}
          JOB_RESULT: ${{ job.status }}
        run: |
          mkdir -p results
          jq -n \
            --arg scenario "$SCENARIO" \
            --arg mode "real" \
            --arg batch "batch5-real-claude" \
            --arg status "$STATUS" \
            --arg issue_number "$ISSUE_NUMBER" \
            --arg error "$ERROR_MSG" \
            --arg job_result "$JOB_RESULT" \
            '{scenario: $scenario, mode: $mode, batch: $batch, status: $status, issue_number: $issue_number, error: $error, job_result: $job_result}' \
            > results/${{ matrix.scenario }}-real.json

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: result-batch5-${{ matrix.scenario }}
          path: results/
          retention-days: 1

      - name: Fail job if test failed
        if: always() && steps.run.outputs.status != 'completed'
        run: |
          echo "Test failed with status: ${{ steps.run.outputs.status }}"
          echo "Error: ${{ steps.run.outputs.error }}"
          exit 1

  # ============================================================================
  # CLAUDE ANALYSIS: Analyze results and propose solutions
  # ============================================================================
  claude-analysis:
    needs: [batch1-mock, batch2-edge-cases, batch3-mock, batch4-mock, batch5-real-claude]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '22'
      - uses: pnpm/action-setup@v4
      - run: pnpm install --frozen-lockfile
      - run: pnpm --filter @more/prompts compile
      - name: Build actions
        run: cd .github/actions-ts && pnpm run build

      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          pattern: result-*
          path: all-results
          merge-multiple: true

      - name: Aggregate results
        id: aggregate
        env:
          BATCH1_RESULT: ${{ needs.batch1-mock.result }}
          BATCH2_RESULT: ${{ needs.batch2-edge-cases.result }}
          BATCH3_RESULT: ${{ needs.batch3-mock.result }}
          BATCH4_RESULT: ${{ needs.batch4-mock.result }}
          BATCH5_RESULT: ${{ needs.batch5-real-claude.result }}
          RUN_ID: ${{ github.run_id }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          BRANCH: ${{ github.ref_name }}
          COMMIT: ${{ github.sha }}
        run: |
          # Combine all JSON files into a single array
          RESULTS=$(find all-results -name "*.json" -exec cat {} \; | jq -s '.')

          # Count results
          TOTAL=$(echo "$RESULTS" | jq 'length')
          PASSED=$(echo "$RESULTS" | jq '[.[] | select(.status == "completed")] | length')
          FAILED=$(echo "$RESULTS" | jq '[.[] | select(.status != "completed")] | length')

          # Create summary
          SUMMARY="Total: $TOTAL | Passed: $PASSED | Failed: $FAILED"

          if [[ "$FAILED" -gt 0 ]]; then
            HAS_FAILURES="true"
          else
            HAS_FAILURES="false"
          fi

          # Build enriched results file with workflow metadata
          jq -n \
            --arg run_id "$RUN_ID" \
            --arg run_url "$RUN_URL" \
            --arg branch "$BRANCH" \
            --arg commit "$COMMIT" \
            --arg batch1 "$BATCH1_RESULT" \
            --arg batch2 "$BATCH2_RESULT" \
            --arg batch3 "$BATCH3_RESULT" \
            --arg batch4 "$BATCH4_RESULT" \
            --arg batch5 "$BATCH5_RESULT" \
            --arg summary "$SUMMARY" \
            --argjson results "$RESULTS" \
            '{
              workflow: {
                run_id: $run_id,
                run_url: $run_url,
                branch: $branch,
                commit: $commit,
                batches: {
                  "batch1-mock": $batch1,
                  "batch2-edge-cases": $batch2,
                  "batch3-mock": $batch3,
                  "batch4-mock": $batch4,
                  "batch5-real-claude": $batch5
                }
              },
              summary: $summary,
              results: $results
            }' > /tmp/all_results.json

          echo "summary=$SUMMARY" >> $GITHUB_OUTPUT
          echo "has_failures=$HAS_FAILURES" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT

          # Output summary
          echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**$SUMMARY**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # List failures
          if [[ "$HAS_FAILURES" == "true" ]]; then
            echo "### Failures" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            echo "$RESULTS" | jq '[.[] | select(.status != "completed")]' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### All Results" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo "$RESULTS" | jq '.' >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Install Claude Code
        run: |
          set -e
          curl -fsSL https://claude.ai/install.sh | bash
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Collect scenario context for failures
        id: scenario-docs
        if: steps.aggregate.outputs.has_failures == 'true'
        run: |
          DOCS=""
          SCENARIOS_DIR="packages/statemachine/actions/sm-test-runner/fixtures/scenarios"
          DISCUSSION_DIR="packages/statemachine/actions/sm-test-runner/fixtures/discussion/scenarios"

          # Extract failed scenario names from results
          FAILED=$(jq -r '.results[] | select(.status != "completed" or .job_result == "failure") | .scenario' /tmp/all_results.json | sort -u)

          for scenario in $FAILED; do
            # Check issue scenarios first, then discussion scenarios
            if [ -f "$SCENARIOS_DIR/$scenario/README.md" ]; then
              DOCS+="$(cat "$SCENARIOS_DIR/$scenario/README.md")"
              DOCS+=$'\n\n---\n\n'
            elif [ -f "$DISCUSSION_DIR/$scenario/README.md" ]; then
              DOCS+="$(cat "$DISCUSSION_DIR/$scenario/README.md")"
              DOCS+=$'\n\n---\n\n'
            fi
          done

          echo "$DOCS" > /tmp/scenario_docs.md

      - name: Run Claude Analysis
        id: analysis
        uses: ./packages/statemachine/actions/sm-claude
        with:
          prompt_dir: test-analysis
          prompt_vars: >-
            {
              "TEST_RESULTS_FILE": "/tmp/all_results.json",
              "SCENARIO_DOCS_FILE": "${{ steps.aggregate.outputs.has_failures == 'true' && '/tmp/scenario_docs.md' || '' }}"
            }
          allowed_tools: "Read,Bash"
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}

      - name: Write analysis to summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Claude Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "${{ steps.analysis.outputs.output }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "**Stats:** ${{ steps.analysis.outputs.num_turns }} turns | \$${{ steps.analysis.outputs.cost_usd }} cost" >> $GITHUB_STEP_SUMMARY

      - name: Final Status
        if: always()
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [[ "${{ steps.aggregate.outputs.has_failures }}" == "true" ]]; then
            echo "## ❌ Some Tests Failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**${{ steps.aggregate.outputs.failed }}** out of **${{ steps.aggregate.outputs.total }}** tests failed." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "See Claude analysis above for recommendations." >> $GITHUB_STEP_SUMMARY
            # Fail the workflow when tests fail
            exit 1
          else
            echo "## ✅ All Tests Passed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All **${{ steps.aggregate.outputs.total }}** tests completed successfully." >> $GITHUB_STEP_SUMMARY
          fi
